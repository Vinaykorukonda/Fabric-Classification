python libraries used :- tensorflow,numpy,streamlit

------------------------------------------------------------------------------------------------------------------
#importing libraries
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten#Fetch Images count from Folders

----------------------------------------------------------------------------------------------------------------------

#Fetch Images count from Folders

---------------------------------

count = 0
dirs = os.listdir('Pictures/')
for dir in dirs:
    files = list(os.listdir('Pictures/'+dir))
    print( dir +' Folder has '+ str(len(files)) + 'Pictures')
    count = count + len(files)
print( 'Pictures Folder has '+ str(count) + 'Pictures')

--------------------------------------------------------------------------------------------------------------------

base_dir = 'Pictures/'
img_size = 180
batch = 32

--------------------------------

train_ds = tf.keras.utils.image_dataset_from_directory( base_dir,
                                                        seed = 123,
                                                        validation_split=0.2,
                                                        subset = 'training',
                                                        batch_size=batch,
                                                        image_size=(img_size,img_size))

val_ds = tf.keras.utils.image_dataset_from_directory( base_dir,
                                                        seed = 123,
                                                        validation_split=0.2,
                                                        subset = 'validation',
                                                        batch_size=batch,
                                                        image_size=(img_size,img_size))

--------------------------------------------------------------------------------------------------------------------

flower_names = train_ds.class_names
flower_names

------------------------------------------------------------

import matplotlib.pyplot as plt

-------------------------------------------------------------

i = 0
plt.figure(figsize=(10,10))

for pictures, labels in train_ds.take(1):
    for i in range(9):
        plt.subplot(3,3, i+1)
        plt.imshow(pictures[i].numpy().astype('uint8'))
        plt.title(flower_names[labels[i]])
        plt.axis('off')

--------------------------------------------------------------

AUTOTUNE = tf.data.AUTOTUNE

--------------------------------------------------------------

train_ds = train_ds.cache(). shuffle(1000).prefetch(buffer_size = AUTOTUNE)

-------------------------------------------------------------------------------

val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)

-------------------------------------------------------------------------------

#Data Augmentation

-------------------------------------------------------------------------------

data_augmentation = Sequential([
    layers.RandomFlip("horizontal", input_shape = (img_size, img_size,3)),
    layers.RandomRotation(0.1),
    layers. RandomZoom(0.1)
])

---------------------------------------------------------------------------------

i = 0
plt.figure(figsize=(10,10))

for pictures, labels in train_ds.take(1):
    for i in range(6):
        plt.subplot(3,3, i+1)
        plt.imshow(pictures[0].numpy().astype('uint8'))
        plt.axis('off')

---------------------------------------------------------------------------------

#Model Creation

---------------------------------------------------------------------------------

model = Sequential([
    data_augmentation,
    layers.Rescaling(1./255),
    Conv2D(16, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(32, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(64, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Dropout(0.2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(5)
])

-------------------------------------------------------------------------------------

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

--------------------------------------------------------------------------------------

model.summary()

--------------------------------------------------------------------------------------

history = model.fit(train_ds,  epochs=15, validation_data=val_ds)

--------------------------------------------------------------------------------------

def classify_images(image_path):
    input_image = tf.keras.utils.load_img(image_path, target_size=(180,180))
    input_image_array = tf.keras.utils.img_to_array(input_image)
    input_image_exp_dim = tf.expand_dims(input_image_array,0)
    
    predictions = model.predict(input_image_exp_dim)
    result = tf.nn.softmax(predictions[0])
    outcome = 'The Image belongs to ' + flower_names[np.argmax(result)] + ' with a score of '+ str(np.max(result)*100)
    return outcome

--------------------------------------------------------------------------------------------------------------------

classify_images('Case/nylon.jpg')

----------------------------------------------------------

model.save('Fabric_C_Model.keras')



---------------------------------------------END-------------------------------------------------------------------
VS code

import os
import keras
from keras.models import load_model
import streamlit as st 
import tensorflow as tf
import numpy as np

# Set page title
st.header(' Fabric Classification Model')

# Make sure upload directory exists
UPLOAD_DIR = 'upload'
os.makedirs(UPLOAD_DIR, exist_ok=True)

# Corrected variable name: 'fabric_names' instead of 'fabric_name'
fabric_names = ['cotton', 'denim', 'nylon', 'polyester', 'silk']

# Load model safely
MODEL_PATH = 'Fabric_C_Model.keras'
try:
    model = load_model(MODEL_PATH)
except Exception as e:
    st.error(f"Failed to load model: {e}")
    st.stop()

# Function to classify uploaded image
def classify_pictures(image_path):
    input_image = tf.keras.utils.load_img(image_path, target_size=(180, 180))
    input_image_array = tf.keras.utils.img_to_array(input_image)
    input_image_exp_dim = tf.expand_dims(input_image_array, 0)  # Shape: (1, 180, 180, 3)

    predictions = model.predict(input_image_exp_dim)
    result = tf.nn.softmax(predictions[0])
    outcome = f"üåº The image most likely belongs to **{fabric_names[np.argmax(result)]}** with a confidence of **{np.max(result) * 100:.2f}%**."
    return outcome

# Streamlit uploader
uploaded_file = st.file_uploader('üìÅ Upload an image', type=['jpg', 'jpeg', 'png'])
if uploaded_file is not None:
    # Save the uploaded file
    saved_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
    with open(saved_path, 'wb') as f:
        f.write(uploaded_file.getbuffer())

    # Display uploaded image
    st.image(uploaded_file, width=200)

    # Classify and display result
    prediction = classify_pictures(saved_path)
    st.markdown(prediction)
